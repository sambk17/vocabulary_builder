{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Identify Text to Use\n",
    "\n",
    "* I'm using a book, but long term goal would be easy-to-consume articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('test_article.txt', 'r') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"May is quiet in government meetings, too. \\\\'93She sits, you talk. She sits. She looks at you, and then you leave,\\\\'94 a former Cabinet colleague told me recently. May\\\\'92s preferred method of communicating with the public is in the form of long speeches, which she delivers with a certain steel. She can land a joke, if she has time to prepare. But when she is forced to speak off the cuff, in Parliament or to the press, her body stiffens and she takes deep breaths. She has a wide, expressive mouth that cracks into grimaces and betrays an inner tumult, while the sentences that emerge are frequently circular and devoid of clear meaning.\\\\\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokens = []\n",
    "for i in data:\n",
    "    sent_tokens.append(sent_tokenize(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [sent for sent in map(word_tokenize, data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_lower = [[word.lower() for word in sent]\n",
    "                 for sent in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation_ = set(string.punctuation)\n",
    "\n",
    "def filter_tokens(sent):\n",
    "    return([w for w in sent if not w in punctuation_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'british',\n",
       " 'prime',\n",
       " 'minister',\n",
       " 'theresa',\n",
       " 'may',\n",
       " 'often',\n",
       " 'strikes',\n",
       " 'people',\n",
       " 'as',\n",
       " 'cautious',\n",
       " 'but',\n",
       " 'her',\n",
       " 'political',\n",
       " 'career',\n",
       " 'has',\n",
       " 'been',\n",
       " 'defined',\n",
       " 'by',\n",
       " 'acts',\n",
       " 'of',\n",
       " 'boldness',\n",
       " 'often',\n",
       " 'on',\n",
       " 'behalf',\n",
       " 'of',\n",
       " 'unfashionable',\n",
       " 'causes',\n",
       " 'or',\n",
       " 'in',\n",
       " 'the',\n",
       " 'face',\n",
       " 'of',\n",
       " 'seemingly',\n",
       " 'impossible',\n",
       " 'circumstances',\n",
       " 'the',\n",
       " 'misconception',\n",
       " 'arises',\n",
       " 'in',\n",
       " 'part',\n",
       " 'because',\n",
       " 'she',\n",
       " 'is',\n",
       " 'an',\n",
       " 'awkward',\n",
       " 'person',\n",
       " 'may',\n",
       " 'who',\n",
       " 'is',\n",
       " 'sixty-one',\n",
       " 'is',\n",
       " 'tall',\n",
       " 'and',\n",
       " 'stooped',\n",
       " 'serious',\n",
       " 'and',\n",
       " 'shy',\n",
       " 'since',\n",
       " 'she',\n",
       " 'was',\n",
       " 'elected',\n",
       " 'to',\n",
       " 'parliament',\n",
       " 'in',\n",
       " 'the',\n",
       " 'late',\n",
       " 'nineteen-nineties',\n",
       " 'she',\n",
       " 'has',\n",
       " 'dressed',\n",
       " 'in',\n",
       " 'sharp',\n",
       " 'eye-catching',\n",
       " 'clothes',\n",
       " 'as',\n",
       " 'if',\n",
       " 'to',\n",
       " 'offset',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'that',\n",
       " 'she',\n",
       " 'is',\n",
       " 'not',\n",
       " 'personally',\n",
       " 'vivacious',\n",
       " 'but',\n",
       " 'the',\n",
       " 'effect',\n",
       " 'is',\n",
       " 'often',\n",
       " 'to',\n",
       " 'accentuate',\n",
       " 'what',\n",
       " 'is',\n",
       " 'not',\n",
       " 'there',\n",
       " 'may',\n",
       " \"doesn\\\\'92t\",\n",
       " 'say',\n",
       " 'much',\n",
       " 'by',\n",
       " \"anyone\\\\'92s\",\n",
       " 'standard',\n",
       " 'let',\n",
       " 'alone',\n",
       " 'that',\n",
       " 'of',\n",
       " 'a',\n",
       " 'politician',\n",
       " 'on',\n",
       " 'a',\n",
       " 'recent',\n",
       " 'sunny',\n",
       " 'afternoon',\n",
       " 'in',\n",
       " 'the',\n",
       " 'garden',\n",
       " 'of',\n",
       " 'the',\n",
       " 'prime',\n",
       " \"minister\\\\'92s\",\n",
       " 'residence',\n",
       " 'at',\n",
       " '10',\n",
       " 'downing',\n",
       " 'street',\n",
       " 'i',\n",
       " 'watched',\n",
       " 'her',\n",
       " 'being',\n",
       " 'guided',\n",
       " 'by',\n",
       " 'an',\n",
       " 'aide',\n",
       " 'through',\n",
       " 'the',\n",
       " 'beginning',\n",
       " 'of',\n",
       " 'a',\n",
       " 'party',\n",
       " 'to',\n",
       " 'mark',\n",
       " \"london\\\\'92s\",\n",
       " 'pride',\n",
       " 'celebrations',\n",
       " 'as',\n",
       " 'may',\n",
       " 'was',\n",
       " 'introduced',\n",
       " 'to',\n",
       " 'a',\n",
       " 'line',\n",
       " 'of',\n",
       " 'leaders',\n",
       " 'from',\n",
       " \"britain\\\\'92s\",\n",
       " 'gay',\n",
       " 'and',\n",
       " 'transgender',\n",
       " 'communities',\n",
       " 'she',\n",
       " 'smiled',\n",
       " 'each',\n",
       " 'time',\n",
       " 'and',\n",
       " 'then',\n",
       " 'started',\n",
       " 'to',\n",
       " 'nod',\n",
       " 'she',\n",
       " 'nodded',\n",
       " 'faster',\n",
       " 'dozens',\n",
       " 'of',\n",
       " 'times',\n",
       " 'to',\n",
       " 'encourage',\n",
       " 'them',\n",
       " 'to',\n",
       " 'say',\n",
       " 'more',\n",
       " 'she',\n",
       " 'extended',\n",
       " 'her',\n",
       " 'neck',\n",
       " 'like',\n",
       " 'a',\n",
       " 'bird',\n",
       " 'leaning',\n",
       " 'over',\n",
       " 'a',\n",
       " 'pond',\n",
       " 'nodded',\n",
       " 'a',\n",
       " 'final',\n",
       " 'time',\n",
       " 'and',\n",
       " 'moved',\n",
       " 'on',\n",
       " 'she',\n",
       " 'scarcely',\n",
       " 'said',\n",
       " 'a',\n",
       " 'word.\\\\']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_filtered = list(map(filter_tokens, tokens_lower))\n",
    "tokens_filtered[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Identify vocab words to substitute\n",
    "\n",
    "* Identify words, research word2vec and how to evaluate the word\n",
    "* Look at synonyms and antonyms\n",
    "* https://www.geeksforgeeks.org/get-synonymsantonyms-nltk-wordnet-python/\n",
    "* http://www.nltk.org/howto/wordnet.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def close_word(my_word):\n",
    "\n",
    "    synonyms = [] \n",
    "    antonyms = [] \n",
    "\n",
    "    for syn in wordnet.synsets(str(my_word)): \n",
    "        for l in syn.lemmas(): \n",
    "            synonyms.append(l.name()) \n",
    "            if l.antonyms(): \n",
    "                antonyms.append(l.antonyms()[0].name()) \n",
    "    return set(synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Nice',\n",
       " 'courteous',\n",
       " 'dainty',\n",
       " 'decent',\n",
       " 'gracious',\n",
       " 'nice',\n",
       " 'overnice',\n",
       " 'prissy',\n",
       " 'skillful',\n",
       " 'squeamish'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonyms = close_word(\"nice\")\n",
    "synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measured_words(my_word):\n",
    "    synonyms = close_word(my_word)\n",
    "    w1 = wordnet.synset(my_word)\n",
    "    for word in synonyms:\n",
    "        print(w1.wup_similarity(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-c262a350af4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmeasured_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nice\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-cf2d23ecc28a>\u001b[0m in \u001b[0;36mmeasured_words\u001b[0;34m(my_word)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmeasured_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msynonyms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclose_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mw1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msynonyms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwup_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36msynset\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1288\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msynset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m         \u001b[0;31m# split name into lemma, part of speech and synset number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1290\u001b[0;31m         \u001b[0mlemma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msynset_index_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1291\u001b[0m         \u001b[0msynset_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msynset_index_str\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 1)"
     ]
    }
   ],
   "source": [
    "measured_words(\"nice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = wordnet.synset('happy.a.01')\n",
    "w2 = wordnet.synset('felicitous.a.01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baby',\n",
       " 'child',\n",
       " 'fry',\n",
       " 'kid',\n",
       " 'minor',\n",
       " 'nestling',\n",
       " 'nipper',\n",
       " 'shaver',\n",
       " 'small_fry',\n",
       " 'tiddler',\n",
       " 'tike',\n",
       " 'tyke',\n",
       " 'youngster'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close_word(\"child\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('child.n.01'),\n",
       " Synset('child.n.02'),\n",
       " Synset('child.n.03'),\n",
       " Synset('child.n.04')]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordnet.synsets('child')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('happy.a.01'),\n",
       " Synset('felicitous.s.02'),\n",
       " Synset('glad.s.02'),\n",
       " Synset('happy.s.04')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordnet.synsets('happy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('juvenile.n.01')]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordnet.synset('child.n.01').hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(w1.wup_similarity(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
