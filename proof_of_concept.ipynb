{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Identify Text to Use\n",
    "\n",
    "* I'm using a book, but long term goal would be easy-to-consume articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('test_article.txt', 'r') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"May is quiet in government meetings, too. \\\\'93She sits, you talk. She sits. She looks at you, and then you leave,\\\\'94 a former Cabinet colleague told me recently. May\\\\'92s preferred method of communicating with the public is in the form of long speeches, which she delivers with a certain steel. She can land a joke, if she has time to prepare. But when she is forced to speak off the cuff, in Parliament or to the press, her body stiffens and she takes deep breaths. She has a wide, expressive mouth that cracks into grimaces and betrays an inner tumult, while the sentences that emerge are frequently circular and devoid of clear meaning.\\\\\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokens = []\n",
    "for i in data:\n",
    "    sent_tokens.append(sent_tokenize(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [sent for sent in map(word_tokenize, data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_lower = [[word.lower() for word in sent]\n",
    "                 for sent in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation_ = set(string.punctuation)\n",
    "\n",
    "def filter_tokens(sent):\n",
    "    return([w for w in sent if not w in punctuation_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'british',\n",
       " 'prime',\n",
       " 'minister',\n",
       " 'theresa',\n",
       " 'may',\n",
       " 'often',\n",
       " 'strikes',\n",
       " 'people',\n",
       " 'as',\n",
       " 'cautious',\n",
       " 'but',\n",
       " 'her',\n",
       " 'political',\n",
       " 'career',\n",
       " 'has',\n",
       " 'been',\n",
       " 'defined',\n",
       " 'by',\n",
       " 'acts',\n",
       " 'of',\n",
       " 'boldness',\n",
       " 'often',\n",
       " 'on',\n",
       " 'behalf',\n",
       " 'of',\n",
       " 'unfashionable',\n",
       " 'causes',\n",
       " 'or',\n",
       " 'in',\n",
       " 'the',\n",
       " 'face',\n",
       " 'of',\n",
       " 'seemingly',\n",
       " 'impossible',\n",
       " 'circumstances',\n",
       " 'the',\n",
       " 'misconception',\n",
       " 'arises',\n",
       " 'in',\n",
       " 'part',\n",
       " 'because',\n",
       " 'she',\n",
       " 'is',\n",
       " 'an',\n",
       " 'awkward',\n",
       " 'person',\n",
       " 'may',\n",
       " 'who',\n",
       " 'is',\n",
       " 'sixty-one',\n",
       " 'is',\n",
       " 'tall',\n",
       " 'and',\n",
       " 'stooped',\n",
       " 'serious',\n",
       " 'and',\n",
       " 'shy',\n",
       " 'since',\n",
       " 'she',\n",
       " 'was',\n",
       " 'elected',\n",
       " 'to',\n",
       " 'parliament',\n",
       " 'in',\n",
       " 'the',\n",
       " 'late',\n",
       " 'nineteen-nineties',\n",
       " 'she',\n",
       " 'has',\n",
       " 'dressed',\n",
       " 'in',\n",
       " 'sharp',\n",
       " 'eye-catching',\n",
       " 'clothes',\n",
       " 'as',\n",
       " 'if',\n",
       " 'to',\n",
       " 'offset',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'that',\n",
       " 'she',\n",
       " 'is',\n",
       " 'not',\n",
       " 'personally',\n",
       " 'vivacious',\n",
       " 'but',\n",
       " 'the',\n",
       " 'effect',\n",
       " 'is',\n",
       " 'often',\n",
       " 'to',\n",
       " 'accentuate',\n",
       " 'what',\n",
       " 'is',\n",
       " 'not',\n",
       " 'there',\n",
       " 'may',\n",
       " \"doesn\\\\'92t\",\n",
       " 'say',\n",
       " 'much',\n",
       " 'by',\n",
       " \"anyone\\\\'92s\",\n",
       " 'standard',\n",
       " 'let',\n",
       " 'alone',\n",
       " 'that',\n",
       " 'of',\n",
       " 'a',\n",
       " 'politician',\n",
       " 'on',\n",
       " 'a',\n",
       " 'recent',\n",
       " 'sunny',\n",
       " 'afternoon',\n",
       " 'in',\n",
       " 'the',\n",
       " 'garden',\n",
       " 'of',\n",
       " 'the',\n",
       " 'prime',\n",
       " \"minister\\\\'92s\",\n",
       " 'residence',\n",
       " 'at',\n",
       " '10',\n",
       " 'downing',\n",
       " 'street',\n",
       " 'i',\n",
       " 'watched',\n",
       " 'her',\n",
       " 'being',\n",
       " 'guided',\n",
       " 'by',\n",
       " 'an',\n",
       " 'aide',\n",
       " 'through',\n",
       " 'the',\n",
       " 'beginning',\n",
       " 'of',\n",
       " 'a',\n",
       " 'party',\n",
       " 'to',\n",
       " 'mark',\n",
       " \"london\\\\'92s\",\n",
       " 'pride',\n",
       " 'celebrations',\n",
       " 'as',\n",
       " 'may',\n",
       " 'was',\n",
       " 'introduced',\n",
       " 'to',\n",
       " 'a',\n",
       " 'line',\n",
       " 'of',\n",
       " 'leaders',\n",
       " 'from',\n",
       " \"britain\\\\'92s\",\n",
       " 'gay',\n",
       " 'and',\n",
       " 'transgender',\n",
       " 'communities',\n",
       " 'she',\n",
       " 'smiled',\n",
       " 'each',\n",
       " 'time',\n",
       " 'and',\n",
       " 'then',\n",
       " 'started',\n",
       " 'to',\n",
       " 'nod',\n",
       " 'she',\n",
       " 'nodded',\n",
       " 'faster',\n",
       " 'dozens',\n",
       " 'of',\n",
       " 'times',\n",
       " 'to',\n",
       " 'encourage',\n",
       " 'them',\n",
       " 'to',\n",
       " 'say',\n",
       " 'more',\n",
       " 'she',\n",
       " 'extended',\n",
       " 'her',\n",
       " 'neck',\n",
       " 'like',\n",
       " 'a',\n",
       " 'bird',\n",
       " 'leaning',\n",
       " 'over',\n",
       " 'a',\n",
       " 'pond',\n",
       " 'nodded',\n",
       " 'a',\n",
       " 'final',\n",
       " 'time',\n",
       " 'and',\n",
       " 'moved',\n",
       " 'on',\n",
       " 'she',\n",
       " 'scarcely',\n",
       " 'said',\n",
       " 'a',\n",
       " 'word.\\\\']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_filtered = list(map(filter_tokens, tokens_lower))\n",
    "tokens_filtered[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Identify vocab words to substitute\n",
    "\n",
    "* Identify words, research word2vec and how to evaluate the word\n",
    "* Look at synonyms and antonyms\n",
    "* https://www.geeksforgeeks.org/get-synonymsantonyms-nltk-wordnet-python/\n",
    "* http://www.nltk.org/howto/wordnet.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def close_words(my_word):\n",
    "\n",
    "    synonyms = [] \n",
    "    antonyms = [] \n",
    "\n",
    "    for syn in wordnet.synsets(str(my_word)): \n",
    "        for l in syn.lemmas(): \n",
    "            synonyms.append(l.name()) \n",
    "            if l.antonyms(): \n",
    "                antonyms.append(l.antonyms()[0].name()) \n",
    "    return set(synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Nice',\n",
       " 'courteous',\n",
       " 'dainty',\n",
       " 'decent',\n",
       " 'gracious',\n",
       " 'nice',\n",
       " 'overnice',\n",
       " 'prissy',\n",
       " 'skillful',\n",
       " 'squeamish'}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonyms = close_words(\"nice\")\n",
    "synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measured_words(my_word, other_word):\n",
    "    synonyms = close_words(my_word)\n",
    "    w2 = wordnet.synsets(other_word)\n",
    "    combo = {}\n",
    "    for word in synonyms:\n",
    "        w1 = wordnet.synsets(word)\n",
    "        for one in w1:\n",
    "            for two in w2:\n",
    "                if wordnet.path_similarity(one, two) is None:\n",
    "                    continue\n",
    "                combo['%s: %s' % (one, two)] = wordnet.path_similarity(one, two)\n",
    "    if not combo:\n",
    "        combo['%s: %s' % (one, two)] = 0\n",
    "        return combo\n",
    "    return max(combo.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"Synset('dainty.s.04'): Synset('happy.s.04')\": 0}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measured_words(\"nice\", \"happy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_passage(my_word, passage):\n",
    "    passage_dict = {}\n",
    "    for word in passage:\n",
    "        passage_dict[measured_words(my_word, word)[0]] = measured_words(my_word, word)[1]\n",
    "    return passage_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'two' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-d3c5c667e5b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0miterate_passage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nice\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokens_filtered\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-119-7c64a0bab87d>\u001b[0m in \u001b[0;36miterate_passage\u001b[0;34m(my_word, passage)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mpassage_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpassage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mpassage_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmeasured_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeasured_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpassage_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-117-7b1a963da35b>\u001b[0m in \u001b[0;36mmeasured_words\u001b[0;34m(my_word, other_word)\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0mcombo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'%s: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtwo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtwo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcombo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mcombo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'%s: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtwo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcombo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'two' referenced before assignment"
     ]
    }
   ],
   "source": [
    "iterate_passage(\"nice\",tokens_filtered[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
